





# ═════════════════════════════════════════════════════════════════════════════
#  v
# Release: 
# Image: 
# 
# ═════════════════════════════════════════════════════════════════════════════


[Unit]
Description=Open WebUI - LLM Chat Interface
After=network-online.target llm.network.service
Requires=llm.network.service



After=searxng.service
Wants=searxng.service

After=tika.service
Wants=tika.service

After=jupyter.service
Wants=jupyter.service


[Container]
Image=
AutoUpdate=registry
ContainerName=openwebui

# ═════════════════════════════════════════════════════════════════════════════
# 🌐 NETWORK
# ═════════════════════════════════════════════════════════════════════════════
Network=llm.network

# ═════════════════════════════════════════════════════════════════════════════
# 📍 PUBLISHED PORT - Using macro
# ═════════════════════════════════════════════════════════════════════════════
PublishPort=127.0.0.1:3000:8080


# ═════════════════════════════════════════════════════════════════════════════
# 💾 VOLUME - Using macro
# ═════════════════════════════════════════════════════════════════════════════
Volume=openwebui.volume:/app/backend/data:Z


# ═════════════════════════════════════════════════════════════════════════════
# 🔐 ENVIRONMENT - Loaded from dedicated env file
# ═════════════════════════════════════════════════════════════════════════════
EnvironmentFile=%h/.config/containers/systemd/openwebui/openwebui.env

# ═════════════════════════════════════════════════════════════════════════════
# 🔧 HEALTH CHECK - Using macro
# ═════════════════════════════════════════════════════════════════════════════
HealthCmd=wget --no-verbose --tries=1 --spider http://localhost:8080/health || exit 1
HealthInterval=30s
HealthTimeout=5s
HealthRetries=3
HealthStartPeriod=30s


# ═════════════════════════════════════════════════════════════════════════════
# 🚀 SERVICE - Using macro
# ═════════════════════════════════════════════════════════════════════════════
[Service]
Slice=llm.slice
TimeoutStartSec=900
Restart=on-failure
RestartSec=10


[Install]
# No WantedBy - dependencies via After/Requires

# ═════════════════════════════════════════════════════════════════════════════
# 📝 ARCHITECTURE NOTES
# ═════════════════════════════════════════════════════════════════════════════
#
# DEPENDENCIES:
#   - openwebui_postgres (database)
#   - openwebui_redis (cache and websockets)
#   - litellm (LLM backend)
#   - Optional: searxng, tika, jupyter, whisper (feature-dependent)
#
# FEATURES ENABLED:
#   ✓ rag
#   ✓ web_search
#   ✓ code_execution
#   ✓ title_generation
#   ✓ autocomplete_generation
#   ✓ tags_generation
#   ✓ websocket_support
#
# PROVIDERS:
#   → vector_db: qdrant
#   → rag_embedding: openai
#   → content_extraction: tika
#   → text_splitter: recursive
#   → web_search_engine: searxng
#   → web_loader: requests
#   → image_engine: openai
#   → stt_engine: openai
#   → tts_engine: openai
#   → code_execution_engine: jupyter
#   → code_interpreter_engine: jupyter
#   → storage_provider: 
#   → auth_provider: local
#
# ═════════════════════════════════════════════════════════════════════════════
